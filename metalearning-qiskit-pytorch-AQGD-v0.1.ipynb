{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Function\n",
    "\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/dumon/Documents/Personal/quantum/ibm-qiskitcamp/qiskit-terra/qiskit/pulse/channels/pulse_channels.py:25: DeprecationWarning: Channels have been migrated. Please use `from qiskit.pulse.channels import X` rather than `from qiskit.pulse.channels.pulse_channels import X`.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from qiskit import QuantumRegister,QuantumCircuit,ClassicalRegister,execute\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import Aer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2L(nn.Module):\n",
    "    '''\n",
    "        define Learning-2-Learn class with LSTM architecture\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, circ_function, num_feats=1, batch_size=16):\n",
    "        # circ_function should be a function which is a pennylane qnode\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_feats = num_feats  # rnn_output, qnn input params\n",
    "        self.batch_size = batch_size\n",
    "        # does pennylane support circuits that return multiple measurements?\n",
    "        self.rnn_input_size = 1 # qnn output size\n",
    "        self.function = circ_function\n",
    "\n",
    "        # the target is required\n",
    "        self.target = None\n",
    "        self.hid_cell = None\n",
    "        self.rnn_output = None\n",
    "        self.qnn_output = None\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.rnn_input_size, hidden_size=self.num_feats, num_layers=1, dropout=0\n",
    "        )\n",
    "\n",
    "    def init_hid_cell(self, seq_len=1):\n",
    "        # concatenate and store all the output tensors here\n",
    "        self.rnn_output = torch.tensor([])\n",
    "        self.qnn_output = torch.zeros(seq_len, self.batch_size, self.rnn_input_size)\n",
    "        \n",
    "        hidden = torch.zeros(seq_len, self.batch_size, self.num_feats)\n",
    "        cell = torch.zeros(seq_len, self.batch_size, self.num_feats)\n",
    "        self.hid_cell = (hidden, cell)\n",
    "\n",
    "    def step(self):\n",
    "        ckt = self.function.apply\n",
    "        assert self.hid_cell is not None\n",
    "    \n",
    "        x = self.qnn_output[[-1], :, :]\n",
    "#         print(f'RNN input {x.shape}')\n",
    "        \n",
    "        rnn_output, self.hid_cell = self.lstm(x, self.hid_cell)\n",
    "        self.rnn_output = torch.cat((self.rnn_output, rnn_output), dim=0)  # dims are : (seq_dim, batch_size, feature_size)\n",
    "        # print(f'RNN output: {rnn_output.shape} RNN hist {self.rnn_output.shape}')\n",
    "        \n",
    "        assert rnn_output.shape[0] == 1\n",
    "        qnn_output = torch.zeros_like(x)\n",
    "#         # qnode can't handle batching; iterate through the batch one at a time\n",
    "#         for i in range(rnn_output.shape[1]):\n",
    "#             qnn_input_batch_element = rnn_output[0, i, :].unsqueeze_(0)\n",
    "#             qnn_output_batch_element = ckt(qnn_input_batch_element)\n",
    "#             assert qnn_output_batch_element.nelement() == self.rnn_input_size\n",
    "#             qnn_output[0, i, :] = qnn_output_batch_element\n",
    "        \n",
    "        #trying with batch\n",
    "        qnn_input_element = rnn_output[0, :, :]\n",
    "        qnn_output_element = ckt(qnn_input_element)\n",
    "#         assert qnn_output_batch_element.nelement() == self.rnn_input_size\n",
    "        qnn_output[0, :, :] = qnn_output_element\n",
    "        \n",
    "        # subtract target value so that loss is simply minimized at 0\n",
    "        qnn_output[0,:,:] = qnn_output[0,:,:] - self.target\n",
    "        # print(f'circuit output: {qnn_output.shape}')\n",
    "        self.qnn_output = torch.cat((self.qnn_output, qnn_output), dim=0)\n",
    "\n",
    "        return self.qnn_output\n",
    "\n",
    "    def loss(self, true=None):\n",
    "        # compare the qnn output to the given target ('true')\n",
    "\n",
    "        # print(f'true: {true.shape}, pred: {self.qnn_output.shape}')\n",
    "        \n",
    "        if true==None:\n",
    "            true = torch.zeros(self.qnn_output.shape)\n",
    "            \n",
    "        assert true.shape == self.qnn_output.shape\n",
    "        \n",
    "        return F.mse_loss(self.qnn_output, true)\n",
    "\n",
    "    def numpy_output(self):\n",
    "        return self.qnn_output.detach().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list\n",
    "\n",
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self,shots):\n",
    "        self.theta = Parameter('Theta')\n",
    "        self.phi = Parameter('Phi')\n",
    "        self.shots = shots\n",
    "        \n",
    "        def create_circuit():\n",
    "            qr = QuantumRegister(1,'q')\n",
    "            cr = ClassicalRegister(1,'c')\n",
    "            ckt = QuantumCircuit(qr,cr)\n",
    "            ckt.h(qr[0])\n",
    "            ckt.barrier()\n",
    "            ckt.ry(self.theta,qr[0])\n",
    "            ckt.barrier()\n",
    "            ckt.measure(qr,cr)\n",
    "            return ckt\n",
    "        \n",
    "        self.circuit = create_circuit()\n",
    "        \n",
    "    def N_qubit_expectation_Z(self, counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects    \n",
    "    \n",
    "    def bind(self, parameters):\n",
    "        [self.theta] = to_numbers(parameters)\n",
    "        self.circuit.data[2][0]._params = to_numbers(parameters)\n",
    "    \n",
    "    def run(self, i):\n",
    "        self.bind(i)\n",
    "        \n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        job_sim = execute(self.circuit,backend,shots=self.shots)\n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,1)\n",
    "\n",
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(shots=100)\n",
    "            \n",
    "        exp_value = []\n",
    "        for j in range(len(i)):\n",
    "            \n",
    "            exp_value.append(ctx.QiskitCirc.run(i[j]))\n",
    "        \n",
    "        result = torch.tensor(exp_value)\n",
    "#         print(result)\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = np.pi/2\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors    \n",
    "        \n",
    "        gradient = []\n",
    "        \n",
    "        for j in range(len(i)):\n",
    "            input_numbers = to_numbers(i[j])\n",
    "            for k in range(len(input_numbers)):\n",
    "                \n",
    "                input_eps_plus = input_numbers\n",
    "                input_eps_plus[k] = input_numbers[k] + eps\n",
    "\n",
    "                exp_value_plus = ctx.QiskitCirc.run(torch.tensor(input_eps_plus))[0]\n",
    "                result_eps_plus = torch.tensor([exp_value_plus])\n",
    "\n",
    "                input_eps_minus = input_numbers\n",
    "                input_eps_minus[k] = input_numbers[k] - eps\n",
    "\n",
    "                exp_value_minus = ctx.QiskitCirc.run(torch.tensor(input_eps_minus))[0]\n",
    "                result_eps_minus = torch.tensor([exp_value_minus])\n",
    "\n",
    "                gradient_result = 0.5 * (result_eps_plus - result_eps_minus)\n",
    "\n",
    "                gradient.append(gradient_result)\n",
    "            \n",
    "#         print(gradient)\n",
    "        result = torch.tensor(gradient)\n",
    "#         print(result)\n",
    "\n",
    "        return result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2LRot(L2L):\n",
    "    def init_target(self):\n",
    "        # pick a random number between 0 and 1 as the target expectation value\n",
    "        self.target = (torch.rand(self.batch_size, self.rnn_input_size) - 0.5) * 2\n",
    "\n",
    "\n",
    "# def circ_function(dev):\n",
    "    \n",
    "#     @qml.qnode(dev, interface='torch')\n",
    "#     def circuit(parameters):\n",
    "#         assert len(parameters) == 3\n",
    "\n",
    "#         phi = 2 * np.pi * parameters[:2]\n",
    "#         theta = 2 * np.pi * parameters[-1]\n",
    "#         qml.RX(phi[0], wires=0)\n",
    "#         qml.RZ(phi[1], wires=1)\n",
    "#         qml.CNOT(wires=[0, 1])\n",
    "#         qml.RX(theta, wires=0)\n",
    "#         return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "#     return circuit\n",
    "\n",
    "circ_function = TorchCircuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [01:35<10:07,  7.07s/it]"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "l2l = L2LRot(circ_function, num_feats=1, batch_size=16)\n",
    "\n",
    "optimizer = optim.Adam(l2l.parameters(), lr=0.1)\n",
    "\n",
    "num_epoch = 100\n",
    "num_steps = 10 #25\n",
    "\n",
    "all_loss = []\n",
    "for epoch_ind in tqdm(range(num_epoch)):\n",
    "\n",
    "    l2l.zero_grad()\n",
    "    l2l.init_hid_cell()\n",
    "    l2l.init_target()\n",
    "\n",
    "    for i in range(num_steps):\n",
    "#         print(i)\n",
    "        l2l.step()\n",
    "\n",
    "    loss = l2l.loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    all_loss.append(loss.item())\n",
    "\n",
    "plt.plot(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define class to call the different optimizers on a device\n",
    "\n",
    "# neural optimizer\n",
    "def neural_optimizer(target):\n",
    "    l2l.batch_size = 1\n",
    "\n",
    "    l2l.init_hid_cell()\n",
    "    l2l.target = torch.tensor([[target]])\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        l2l.step()\n",
    "\n",
    "    return l2l.numpy_output()[1:]\n",
    "\n",
    "# gradient descent\n",
    "def gradient_descent(target, dev, lr=0.1):\n",
    "    circuit = circ_function(dev)\n",
    "\n",
    "    parameters = torch.rand(3, requires_grad=True)\n",
    "\n",
    "    opt = torch.optim.Adam([parameters], lr=lr)\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        opt.zero_grad()\n",
    "        result = circuit(parameters)\n",
    "        loss = torch.abs(result - target) ** 2\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        output.append(result - target)\n",
    "\n",
    "    return output\n",
    "\n",
    "def neldermead(target, dev):\n",
    "\n",
    "    circuit = circ_function(dev)\n",
    "    \n",
    "    def cost(parameters):\n",
    "        result = circuit(parameters)\n",
    "        return torch.abs(result - target) ** 2\n",
    "    \n",
    "    output = []\n",
    "    def callback(x):\n",
    "        fobj = circuit(x)\n",
    "        output.append(fobj)\n",
    "    \n",
    "    initial_par = np.random.rand(3)\n",
    "    opt_parameters = scipy.optimize.minimize(cost, initial_par, method='Nelder-Mead', callback=callback,\n",
    "                                             options={'maxfev': num_steps, 'return_all': False})\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_plots(l2l, dev, target):\n",
    "    l2l.function = circ_function(dev)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (12,7))\n",
    "    start = time.time()\n",
    "    ax.plot(neural_optimizer(target))\n",
    "    stop = time.time()\n",
    "    print('Neural optimizer took %.4f seconds.' %(stop-start))\n",
    "\n",
    "    start = time.time()\n",
    "    ax.plot(gradient_descent(target, dev))\n",
    "    stop = time.time()\n",
    "    print('Gradient descent took %.4f seconds.' %(stop-start))\n",
    "\n",
    "    start = time.time()\n",
    "    nelder_mead = neldermead(target, dev)\n",
    "    ax.plot(np.array(nelder_mead)-target)\n",
    "    stop = time.time()\n",
    "    print('Nelder-Mead took %.4f seconds.' %(stop-start))\n",
    "\n",
    "    ax.legend(['neural optimizer', 'gradient descent', 'nelder_mead'])\n",
    "    ax.set_xlabel('steps'), ax.set_ylabel('error')\n",
    "    ax.set_title('2 qubit rotation (device: %s)' %dev.short_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a target for the expectation value and evaluate on the default.qubit backend\n",
    "target = -0.7\n",
    "dev = dev_default\n",
    "\n",
    "eval_plots(l2l, dev, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_default = qml.device('default.qubit', wires=2)\n",
    "dev_numpy = qml.device('forest.numpy_wavefunction', wires=2)\n",
    "dev_simulator = qml.device('forest.wavefunction', wires=2)\n",
    "\n",
    "dev_pyqvm = qml.device('forest.qvm', device='2q-pyqvm', shots=shots)\n",
    "dev_qvm = qml.device('forest.qvm', device='Aspen-4-2Q-A', shots=shots)\n",
    "# dev_qpu = qml.device('forest.qpu', device='Aspen-4-2Q-A', shots=shots)\n",
    "\n",
    "#set a target for the expectation value and evaluate on backend of your choice\n",
    "target = -0.7\n",
    "dev = dev_qvm\n",
    "\n",
    "eval_plots(l2l, dev, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
