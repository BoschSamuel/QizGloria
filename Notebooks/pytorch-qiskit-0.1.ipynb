{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/dumon/Documents/Personal/quantum/ibm-qiskitcamp/qiskit-terra/qiskit/pulse/channels/pulse_channels.py:25: DeprecationWarning: Channels have been migrated. Please use `from qiskit.pulse.channels import X` rather than `from qiskit.pulse.channels.pulse_channels import X`.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from qiskit import QuantumRegister,QuantumCircuit,ClassicalRegister,execute\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import Aer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list\n",
    "\n",
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self,shots):\n",
    "        self.theta = Parameter('Theta')\n",
    "        self.phi = Parameter('Phi')\n",
    "        self.lam = Parameter('Lambda')\n",
    "        self.shots = shots\n",
    "        \n",
    "        def create_circuit():\n",
    "            qr = QuantumRegister(1,'q')\n",
    "            cr = ClassicalRegister(1,'c')\n",
    "            ckt = QuantumCircuit(qr,cr)\n",
    "            ckt.h(qr[0])\n",
    "            ckt.barrier()\n",
    "            ckt.u3(self.theta,self.phi,self.lam,qr[0])\n",
    "            ckt.barrier()\n",
    "            ckt.measure(qr,cr)\n",
    "            return ckt\n",
    "        \n",
    "        self.circuit = create_circuit()\n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects    \n",
    "    \n",
    "    def bind(self, parameters):\n",
    "        [self.theta,self.phi,self.lam] = to_numbers(parameters)\n",
    "        self.circuit.data[2][0]._params = to_numbers(parameters)\n",
    "    \n",
    "    def run(self, i):\n",
    "        self.bind(i)\n",
    "        \n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        job_sim = execute(self.circuit,backend,shots=self.shots)\n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,1)\n",
    "\n",
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(shots=10000)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i[0])\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = 0.01\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors    \n",
    "        input_numbers = to_numbers(i[0])\n",
    "        gradient = [0,0,0]\n",
    "        \n",
    "        for k in range(len(input_numbers)):\n",
    "            input_eps = input_numbers\n",
    "            input_eps[k] = input_numbers[k] + eps\n",
    "\n",
    "            exp_value = ctx.QiskitCirc.run(torch.tensor(input_eps))[0]\n",
    "            result_eps = torch.tensor([exp_value])\n",
    "            gradient_result = (exp_value - forward_tensor[0][0].item())/eps\n",
    "            gradient[k] = gradient_result\n",
    "            \n",
    "#         print(gradient)\n",
    "        result = torch.tensor([gradient])\n",
    "#         print(result)\n",
    "\n",
    "        return result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f48e8481770>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7400, -0.6600,  0.8800]])\n"
     ]
    }
   ],
   "source": [
    "# x = torch.tensor([np.pi/4, np.pi/4, np.pi/4], requires_grad=True)\n",
    "x = torch.tensor([[0.0, 0.0, 0.0]], requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "y1.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f48a7596048>]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)\n",
    "    return torch.abs(qc(x) - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([[np.pi/4, np.pi/4, np.pi/4]], requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval.item())\n",
    "#     print(loss.item())\n",
    "\n",
    "plt.plot(loss_list)\n",
    "    \n",
    "# print(circuit(phi, theta))\n",
    "# print(cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 20\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size_train = 1\n",
    "batch_size_test = 1\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "labels = mnist_trainset.targets #get labels\n",
    "labels = labels.numpy()\n",
    "idx1 = np.where(labels == 0) #search all zeros\n",
    "idx2 = np.where(labels == 1) # search all ones\n",
    "idx = np.concatenate((idx1[0][0:10],idx2[0][0:10])) # concatenate their indices\n",
    "mnist_trainset.targets = labels[idx] \n",
    "mnist_trainset.data = mnist_trainset.data[idx]\n",
    "\n",
    "print(mnist_trainset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "#         x = np.pi*F.tanh(x)\n",
    "        print(x)\n",
    "        x = qc(x)\n",
    "#         print(x)\n",
    "        x = (x+1)/2\n",
    "        x = torch.cat((x, 1-x), -1)\n",
    "        return x\n",
    "#         return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2786,  0.2090, -0.2184]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1152, -0.0886, -0.0136]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1689, -0.0758, -0.0134]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0985,  0.0167, -0.1019]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2348,  0.0253, -0.0513]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0583, -0.2359, -0.1303]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1418, -0.0449, -0.1071]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2100, -0.2352, -0.2333]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4797, -0.3208,  0.0254]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1151, -0.2707, -0.2813]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3336, -0.1242, -0.1182]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2711, -0.0834, -0.1516]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2301, -0.0510, -0.1991]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2075, -0.1556, -0.0832]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2658, -0.1213, -0.1209]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2425, -0.1130,  0.0032]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1648, -0.0869, -0.1365]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1651, -0.1176, -0.1761]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1944, -0.1037, -0.1911]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1386, -0.0449, -0.1544]], grad_fn=<AddmmBackward>)\n",
      "-0.509675\n",
      "tensor([[ 0.1168, -0.1040, -0.0960]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2736, -0.0107, -0.1226]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0931, -0.1467, -0.1617]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4519, -0.0162, -0.0481]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5705, -0.0263, -0.2028]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2490,  0.0203, -0.1567]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2132, -0.0157, -0.2696]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2323, -0.0471, -0.0763]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0915, -0.1182, -0.2012]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1307, -0.2457, -0.2026]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1313,  0.1200, -0.4596]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0889, -0.2103, -0.2732]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0666, -0.2849, -0.2116]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0436, -0.6072, -0.2834]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2174, -0.2632, -0.3189]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0293, -0.5416, -0.6850]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1347, -0.1629, -0.1439]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0641, -0.3376, -0.4762]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1944, -0.0325, -0.1759]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1062, -0.1422, -0.2536]], grad_fn=<AddmmBackward>)\n",
      "-0.5421299999999999\n",
      "tensor([[ 0.3608, -0.1053, -0.4968]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3518,  0.0487, -0.1462]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0716, -0.1912, -0.0056]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.1265, 0.6303, 0.5253]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2388, -0.0489,  0.0528]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0038, -0.1226, -0.2889]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3162, 0.2622, 0.2448]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9187, 0.8229, 0.2849]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3671, 0.2926, 0.1423]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.5407, -0.5423,  0.1635]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.3148, -1.1419, -0.1897]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2565,  0.4483,  1.1216]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3166, 0.0868, 0.3424]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6635, -1.5144,  1.0938]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4384, 0.2093, 0.2195]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2067, -0.1034,  0.2769]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3016, -0.6119,  2.2297]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3266, 0.0464, 2.7201]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4484, 0.4231, 0.9140]], grad_fn=<AddmmBackward>)\n",
      "tensor([[4.9974, 5.6844, 6.8042]], grad_fn=<AddmmBackward>)\n",
      "-0.4893500000000001\n",
      "tensor([[1.6955, 0.7733, 2.3860]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.6025, -3.4536,  4.3361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0042, -1.9530,  1.6143]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.2377, -6.9473,  5.3268]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9603, -1.8219,  2.9198]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ -5.4509, -15.9618,   6.1837]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1776, -1.1963,  1.0824]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.0737, -5.9440,  4.4815]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ -38.8763, -219.5250,  111.2550]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1205, 0.8101, 0.4890]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1249, -0.0256,  0.0305]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0716, 0.0881, 0.0927]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0440, 0.8581, 0.3134]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1795,  1.7208,  0.5770]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0424,  0.9750,  0.2930]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0751,  1.2686,  0.4049]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1340,  0.0004, -0.0143]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.1348, 0.0394, 0.0396]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0544,  0.7439,  0.1508]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.0929, 0.2711, 0.0761]], grad_fn=<AddmmBackward>)\n",
      "-0.4999349999999999\n",
      "tensor([[ 0.0809, -0.0715, -0.0788]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1914, -0.0632, -0.0006]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0996, -0.0486, -0.0233]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1432,  0.1506, -0.0035]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1927, -0.1031, -0.0557]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2251, -0.0731, -0.0103]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1558, -0.0882, -0.1208]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3655, -0.0597, -0.0808]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1988, -0.0106, -0.0154]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3226, -0.0377,  0.0444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2704, -0.0795, -0.0468]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3311, -0.0394,  0.0158]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2835, -0.0793, -0.0719]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3191, -0.1398, -0.0537]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3322, -0.1341,  0.0507]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2909, -0.1262,  0.0251]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2172, -0.0937, -0.0593]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2846, -0.0876, -0.0571]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3071, -0.1038, -0.0527]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2302, -0.1083, -0.0528]], grad_fn=<AddmmBackward>)\n",
      "-0.49537999999999993\n",
      "tensor([[ 0.3537, -0.1084, -0.0498]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3078, -0.0826, -0.0774]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4852, -0.1167, -0.1915]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2248, -0.1016, -0.1429]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1962, -0.1086, -0.1641]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2591, -0.1522, -0.2080]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1901, -0.1584, -0.2165]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2943, -0.1679, -0.2101]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2846, -0.1586, -0.0928]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3369, -0.1295, -0.1639]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2369, -0.1203, -0.2001]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4169, -0.1198, -0.0574]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4111, -0.0946, -0.0664]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3713, -0.1187, -0.1343]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3853, -0.1002, -0.2260]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2795, -0.1106, -0.1994]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3756, -0.1298, -0.2080]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4849, -0.1003, -0.2054]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3773, -0.1457, -0.2381]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1927, -0.1498, -0.2645]], grad_fn=<AddmmBackward>)\n",
      "-0.5027200000000001\n",
      "tensor([[ 0.2858, -0.1331, -0.2434]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2995, -0.1403, -0.2117]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3650, -0.1049, -0.1390]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2440, -0.1030, -0.2105]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5218, -0.1345, -0.0704]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3990, -0.0988, -0.1050]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3695, -0.1124, -0.1403]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1227, -0.1143, -0.1849]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3254, -0.1519, -0.1753]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2628, -0.1353, -0.1059]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1853, -0.1606, -0.2336]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3254, -0.1267, -0.1557]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2241, -0.1063, -0.1945]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3797, -0.0851, -0.1125]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3952, -0.0357, -0.0539]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3204, -0.0846, -0.0917]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3245, -0.0507, -0.1034]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3193, -0.0350, -0.0934]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3226, -0.0326, -0.1039]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4941, 0.0089, 0.0022]], grad_fn=<AddmmBackward>)\n",
      "-0.49257000000000006\n",
      "tensor([[ 6.2356e-01,  4.3496e-04, -2.7264e-02]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2022, -0.0690, -0.1557]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5133, -0.0242, -0.0024]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3906, -0.0684, -0.1543]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2569, -0.0976, -0.1142]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2286, -0.1025, -0.1160]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3324, -0.1040, -0.1358]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2623, -0.1424, -0.1267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1303, -0.1445, -0.1844]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2606, -0.1350, -0.1503]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1681, -0.1322, -0.1969]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1666, -0.1776, -0.2418]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1412, -0.1556, -0.2256]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1934, -0.1650, -0.2354]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1451, -0.1495, -0.2241]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1531, -0.1864, -0.2014]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1908, -0.1835, -0.1902]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1612, -0.1709, -0.2160]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2086, -0.1730, -0.2098]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1789, -0.1401, -0.1970]], grad_fn=<AddmmBackward>)\n",
      "-0.49833000000000005\n",
      "tensor([[ 0.3714, -0.1445, -0.1013]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5014, -0.1165, -0.1431]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1365, -0.1646, -0.1761]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4720, -0.1262, -0.1444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2186, -0.1877, -0.2089]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3489, -0.1861, -0.1719]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2088, -0.2200, -0.2115]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2480, -0.1760, -0.2202]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2178, -0.2107, -0.2075]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1277, -0.2334, -0.3161]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2583, -0.2453, -0.3093]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2559, -0.2427, -0.2792]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2592, -0.1874, -0.2536]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2549, -0.1887, -0.2572]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0774, -0.2020, -0.2401]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1616, -0.1807, -0.3037]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1134, -0.1442, -0.2433]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3555, -0.1592, -0.1891]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3450, -0.1264, -0.1330]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4018, -0.1462, -0.1726]], grad_fn=<AddmmBackward>)\n",
      "-0.49167999999999995\n",
      "tensor([[ 0.2210, -0.1452, -0.1943]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2518, -0.1555, -0.1449]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2172, -0.1268, -0.1574]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2436, -0.1690, -0.1761]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1060, -0.1693, -0.2035]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1204, -0.1699, -0.1940]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1712, -0.1799, -0.2040]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0802, -0.2329, -0.2373]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0954, -0.2034, -0.2663]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0683, -0.1598, -0.2523]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.0621, -0.2012, -0.2217]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2361, -0.2180, -0.1626]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1452, -0.1917, -0.1880]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1298, -0.1672, -0.1933]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1480, -0.1729, -0.1772]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1645, -0.1477, -0.2143]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3257, -0.1093, -0.0949]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2151, -0.1282, -0.2344]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1979, -0.1499, -0.2429]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1823, -0.1435, -0.1966]], grad_fn=<AddmmBackward>)\n",
      "-0.49263\n",
      "tensor([[ 0.2178, -0.1970, -0.1574]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2074, -0.2065, -0.2029]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2417, -0.1572, -0.1655]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2727, -0.1657, -0.2747]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4018, -0.1130, -0.1695]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1644, -0.1830, -0.2351]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3422, -0.1281, -0.1635]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1254, -0.2170, -0.1894]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2111, -0.1595, -0.1161]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2572, -0.2011, -0.1110]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3269, -0.1668, -0.2054]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3100, -0.1954, -0.0708]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.1678, -0.1983, -0.1996]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3092, -0.1990, -0.1420]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5935, -0.2284, -0.0132]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5132, -0.2091, -0.0361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3077, -0.1353, -0.1192]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3237, -0.1153, -0.1096]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4159, -0.1057, -0.0487]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3825, -0.1532, -0.0660]], grad_fn=<AddmmBackward>)\n",
      "-0.50325\n",
      "tensor([[ 0.2383, -0.1630, -0.2108]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5062, -0.1620, -0.0688]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4562, -0.1210, -0.0522]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4299, -0.1402, -0.1378]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2380, -0.1467, -0.2178]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3239, -0.1599,  0.0145]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2603, -0.1688, -0.1846]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4910, -0.1244,  0.0406]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2869, -0.1725, -0.1407]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3289, -0.0937, -0.0739]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5091, -0.1069,  0.0744]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2758, -0.1900, -0.0782]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2835, -0.1605, -0.1319]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4242, -0.1489, -0.0747]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2173, -0.1288, -0.1354]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3991, -0.1102,  0.0191]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4148, -0.1092,  0.0264]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.2979, -0.1159, -0.1321]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4190, -0.1576, -0.1491]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5026, -0.1711, -0.0007]], grad_fn=<AddmmBackward>)\n",
      "-0.48075\n",
      "tensor([[ 0.4090, -0.0900, -0.1154]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5514, -0.0690, -0.0325]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5299, -0.1138, -0.0055]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3679, -0.1524, -0.0663]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3482, -0.1035, -0.1138]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5164, -0.1153, -0.0893]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4681, -0.1952, -0.1712]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4619, -0.2041, -0.1861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3231, -0.2246, -0.1813]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5007, -0.1729, -0.2303]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5259, -0.1821, -0.1346]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4813, -0.1945, -0.1151]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7633, -0.0836, -0.0675]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4744, -0.1581, -0.1508]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9028, -0.0996,  0.1050]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6137, -0.0703, -0.0525]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9798, -0.1554, -0.1017]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6452, -0.1514,  0.0954]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3992, -0.0807, -0.2104]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.7035e-01, -9.7577e-02,  5.0621e-04]], grad_fn=<AddmmBackward>)\n",
      "-0.4999300000000001\n",
      "tensor([[ 0.5474, -0.1046, -0.0537]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4464, -0.1181, -0.1495]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6484, 0.0425, 0.0109]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5127, -0.0233, -0.0943]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8664, -0.1261,  0.1187]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7936, 0.0077, 0.0712]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8088, -0.0802, -0.0250]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4727, -0.0726, -0.0443]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1247, -0.0867,  0.2139]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4749, -0.1493, -0.1014]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7039, -0.1187, -0.0433]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8507, -0.1378, -0.0358]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4727, -0.0539,  0.0407]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6914, -0.1505,  0.0479]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6034, -0.0719, -0.0334]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5768, -0.0566,  0.0007]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5826, -0.1455, -0.0187]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4997, -0.1476,  0.0337]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8728, -0.1636,  0.1875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3366, -0.0967, -0.1445]], grad_fn=<AddmmBackward>)\n",
      "-0.48943000000000003\n",
      "tensor([[ 0.5778, -0.1913,  0.1071]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4144, -0.0937, -0.0331]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4074, -0.1050, -0.0184]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6297, -0.1571,  0.0163]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4162, -0.2256,  0.0680]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5755, -0.1437, -0.0036]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7167, -0.1451, -0.0874]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4241, -0.2315, -0.0429]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4541, -0.2037, -0.0243]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7081, -0.1720, -0.0628]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5414, -0.1558,  0.0146]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7722, -0.1270,  0.0884]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8710, -0.2773,  0.1323]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5837, -0.0713, -0.0275]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6542, -0.0854, -0.0241]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9432, -0.0878,  0.1698]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7275, -0.0856,  0.0729]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7579, -0.0997,  0.1828]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.0058, -0.0955,  0.1212]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4763, -0.2060,  0.0394]], grad_fn=<AddmmBackward>)\n",
      "-0.5092049999999999\n",
      "tensor([[ 0.5561, -0.1341,  0.0007]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7734, -0.0725,  0.1278]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6274, -0.0838,  0.0077]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4730, -0.1926,  0.0079]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7619, -0.1936,  0.1982]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8396, -0.2119,  0.3280]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3750, -0.1519,  0.0903]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3690, -0.1994,  0.1162]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6889, -0.1317,  0.1391]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9545, -0.2204,  0.3173]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3644, -0.1190,  0.0493]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6777, -0.1080,  0.1234]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3817, -0.1296,  0.0107]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6431, -0.1284,  0.1215]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3872, -0.1550,  0.0747]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7797, -0.1193,  0.2410]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4245, -0.2033,  0.0732]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4161, -0.1876,  0.1548]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1704, -0.1095,  0.2013]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4072, -0.1353, -0.0221]], grad_fn=<AddmmBackward>)\n",
      "-0.5188050000000001\n",
      "tensor([[ 1.0570, -0.1139,  0.3860]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4210, -0.1735,  0.1084]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4602, -0.1755, -0.0591]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4018, -0.2129,  0.0900]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6017, -0.1843,  0.1678]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4484, -0.1990, -0.0560]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3752, -0.2981,  0.1346]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5919, -0.2193,  0.1970]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6093, -0.2405,  0.2093]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5420, -0.1571,  0.0361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3882, -0.2122, -0.0218]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5812, -0.3526,  0.0703]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6258, -0.1812,  0.1003]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5385, -0.2417,  0.1758]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9250, -0.2052,  0.1511]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7640, -0.3063,  0.3743]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9407, -0.2860,  0.2421]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7252, -0.2161,  0.1501]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5181, -0.2297,  0.1444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7742, -0.3127,  0.1445]], grad_fn=<AddmmBackward>)\n",
      "-0.5061950000000001\n",
      "tensor([[ 0.6012, -0.1643,  0.0546]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4068, -0.1442, -0.0487]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8282, -0.2768,  0.2767]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4225, -0.2719,  0.0298]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5312, -0.3340,  0.0791]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3114, -0.1870, -0.0475]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7229, -0.2009,  0.1292]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9095, -0.3125,  0.2309]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5385, -0.2154,  0.1190]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5962, -0.2589,  0.1330]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3316, -0.1550, -0.0491]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5037, -0.1851,  0.0259]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5565, -0.2680, -0.0493]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5983, -0.2752,  0.1783]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8795, -0.3215,  0.2029]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.0080, -0.2057, -0.0459]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4295, -0.2829,  0.0333]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7490, -0.1817,  0.0491]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8863, -0.3542,  0.2596]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4156, -0.2901,  0.0840]], grad_fn=<AddmmBackward>)\n",
      "-0.48697500000000005\n",
      "tensor([[ 0.5224, -0.2335, -0.0722]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4490, -0.2326, -0.0165]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.3193, -0.3700,  0.2804]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7288, -0.3998,  0.1480]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.2099, -0.1921,  0.0306]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4404, -0.2328,  0.0629]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6838, -0.3638,  0.1233]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.0504, -0.2231,  0.1492]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6174, -0.1824,  0.0628]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4881, -0.2352, -0.0280]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4162, -0.2022, -0.0173]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4086, -0.3078,  0.1896]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6109, -0.2790,  0.2503]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6245, -0.1892,  0.1403]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4061, -0.3528,  0.2866]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4487, -0.3223,  0.2173]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9390, -0.1430,  0.1987]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1414, -0.2044,  0.2041]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3439, -0.1901,  0.1201]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6625, -0.2847,  0.3385]], grad_fn=<AddmmBackward>)\n",
      "-0.490965\n",
      "tensor([[ 0.6416, -0.2125,  0.1861]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7439, -0.2747, -0.0580]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6824, -0.3678,  0.1100]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4345, -0.2787,  0.2856]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4658, -0.1752,  0.0893]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7094, -0.1702,  0.2896]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4396, -0.1682,  0.2335]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6696, -0.2017,  0.3891]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4973, -0.3403,  0.4410]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4289, -0.1434,  0.2154]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7312, -0.1984,  0.0905]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7821, -0.1496,  0.2779]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5200, -0.1804,  0.1353]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1022, -0.1788,  0.3136]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4665, -0.2069,  0.2985]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7802, -0.1931,  0.4592]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5635, -0.1530,  0.2467]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9599, -0.2368,  0.7166]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5253, -0.1020,  0.2436]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5207, -0.0939,  0.1581]], grad_fn=<AddmmBackward>)\n",
      "-0.47700999999999993\n",
      "tensor([[ 0.6942, -0.1124,  0.3969]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7536, -0.2454,  0.4832]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8266, -0.1396,  0.4176]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8910, -0.2386,  0.6262]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.0186, -0.4214,  0.6103]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7752, -0.2145,  0.2910]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.0131, -0.3524,  0.7019]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5001, -0.1936,  0.2804]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5672, -0.3050,  0.4223]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7176, -0.2283,  0.1302]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4431, -0.1697,  0.2173]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7315, -0.2051,  0.3944]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5700, -0.2022,  0.2897]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8249, -0.4099,  0.5923]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5902, -0.2036,  0.3018]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3832, -0.1896,  0.2118]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4746, -0.2920,  0.3729]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7849, -0.4019,  0.6478]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4876, -0.1619,  0.3161]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5460, -0.2390,  0.5497]], grad_fn=<AddmmBackward>)\n",
      "-0.47907500000000003\n",
      "tensor([[ 0.4079, -0.1448,  0.2881]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5718, -0.1662,  0.4073]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4948, -0.1823,  0.3195]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6755, -0.2959,  0.6126]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5967, -0.2875,  0.5826]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6396, -0.4024,  0.6477]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4852, -0.3214,  0.5455]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4312, -0.2565,  0.2782]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5460, -0.2422,  0.1950]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6898, -0.2359,  0.4297]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6735, -0.3963,  0.5943]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5661, -0.3621,  0.5073]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4055, -0.4594,  0.5085]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4760, -0.4351,  0.4176]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4448, -0.4640,  0.5758]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4398, -0.3834,  0.5089]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6083, -0.3331,  0.3937]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6205, -0.2913,  0.4260]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6048, -0.4969,  0.6136]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6098, -0.4322,  0.6322]], grad_fn=<AddmmBackward>)\n",
      "-0.4964000000000001\n",
      "tensor([[ 0.4714, -0.2652,  0.3612]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3685, -0.2500,  0.2933]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5092, -0.2701,  0.3964]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3225, -0.2425,  0.2867]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5159, -0.2863,  0.3516]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4123, -0.4829,  0.5096]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3670, -0.3272,  0.3114]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5789, -0.4488,  0.6624]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6469, -0.2936,  0.4971]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5228, -0.2721,  0.4704]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4695, -0.4593,  0.5171]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5651, -0.3085,  0.3365]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4371, -0.4560,  0.6066]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5387, -0.4222,  0.6457]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3917, -0.3137,  0.2964]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4812, -0.3095,  0.4163]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4386, -0.5077,  0.4810]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4409, -0.2995,  0.2701]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7948, -0.3606,  0.5005]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5510, -0.4856,  0.6237]], grad_fn=<AddmmBackward>)\n",
      "-0.5075350000000001\n",
      "tensor([[ 0.5661, -0.3065,  0.3807]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7491, -0.5168,  0.6018]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4010, -0.4745,  0.5284]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5105, -0.2846,  0.4313]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7995, -0.3581,  0.5475]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5714, -0.6337,  0.4937]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6457, -0.3468,  0.3552]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6652, -0.6188,  0.5121]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7968, -0.3203,  0.5164]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5234, -0.3434,  0.3011]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5153, -0.2360,  0.3248]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7833, -0.4401,  0.7715]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6730, -0.2523,  0.3827]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7933, -0.3155,  0.4890]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5817, -0.4204,  0.5831]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5966, -0.4264,  0.7453]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5715, -0.3574,  0.6440]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7106, -0.2724,  0.5460]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5856, -0.2899,  0.4567]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6565, -0.4621,  0.8170]], grad_fn=<AddmmBackward>)\n",
      "-0.5066150000000001\n",
      "tensor([[ 0.7579, -0.2061,  0.4477]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5571, -0.2275,  0.4394]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5177, -0.3339,  0.4690]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7463, -0.2298,  0.2348]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6156, -0.2198,  0.5424]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1959, -0.4423,  0.8906]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7724, -0.4805,  0.8046]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9239, -0.2691,  0.4966]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4882, -0.3803,  0.5512]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8108, -0.3466,  0.6382]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4533, -0.2737,  0.4345]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7963, -0.3867,  0.6864]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5657, -0.3664,  0.7444]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4676, -0.2395,  0.3644]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9299, -0.2604,  0.6079]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6958, -0.4267,  0.6934]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.3803, -0.3652,  0.4909]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8470, -0.2507,  0.5576]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4039, -0.3626,  0.4948]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4864, -0.2325,  0.4330]], grad_fn=<AddmmBackward>)\n",
      "-0.47134\n",
      "tensor([[ 0.5530, -0.3378,  0.5364]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8302, -0.2761,  0.4145]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.0762, -0.4729,  0.8815]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7838, -0.2028,  0.5891]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5796, -0.2798,  0.6880]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7383, -0.1636,  0.2810]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.0500, -0.1860,  0.6401]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7296, -0.2681,  0.6181]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7185, -0.1851,  0.4948]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9256, -0.1501,  0.5563]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1565, -0.1328,  0.4011]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4707, -0.1230,  0.3689]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1530, -0.2463,  0.9852]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.2045, -0.2820,  1.0076]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7304, -0.1495,  0.6002]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7156, -0.0684,  0.5988]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.2589, 0.0032, 0.7914]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7724, -0.0633,  0.6291]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7123, -0.3271,  0.5451]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6757, -0.3627,  0.6654]], grad_fn=<AddmmBackward>)\n",
      "-0.49072999999999983\n",
      "tensor([[ 0.6228, -0.0679,  0.3951]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.2556, -0.3419,  1.0914]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5629, -0.0944,  0.4301]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5665, -0.1320,  0.4562]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7351, -0.1200,  0.5407]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8428, -0.3912,  0.5667]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1864, -0.3622,  0.8198]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.4926, -0.1572,  1.0175]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5748, -0.0776,  0.4896]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1354, -0.0638,  0.8086]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1780, -0.1440,  0.9493]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.3976, -0.0399,  0.9789]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.3424, -0.2415,  1.2041]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.0383, -0.2384,  0.8732]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7100, -0.1533,  0.9309]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.4758, -0.0557,  0.5246]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9882, -0.0295,  0.8558]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.3948, -0.2693,  1.2883]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6410, -0.1983,  0.6335]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7231, -0.0948,  0.7695]], grad_fn=<AddmmBackward>)\n",
      "-0.5076149999999999\n",
      "tensor([[ 0.9230, -0.0991,  0.8767]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9064, -0.1267,  0.7772]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5445, -0.1188,  0.4552]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9254, -0.2871,  0.9655]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7078, -0.2778,  0.7813]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8139, -0.2820,  0.6213]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7121, -0.2920,  0.6375]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7989, -0.1573,  0.6563]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8837, -0.2482,  0.8105]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6565, -0.1455,  0.3614]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.0525, -0.1674,  0.6973]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.2396, -0.1600,  0.6969]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7639, -0.1852,  0.5098]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8967, -0.2394,  0.7302]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.5646, -0.1602,  0.4418]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.0249, -0.1964,  0.6470]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7585, -0.3320,  0.5355]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8105, -0.1407,  0.6918]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9195, -0.0703,  0.5929]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7707, -0.2371,  0.7095]], grad_fn=<AddmmBackward>)\n",
      "-0.494295\n",
      "tensor([[ 1.1504, -0.2650,  0.7775]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.0074, -0.2132,  0.7761]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6812, -0.1555,  0.3584]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8367, -0.1478,  0.2756]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1391, -0.3655,  0.9920]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8070, -0.1350,  0.4672]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8595, -0.1833,  0.6295]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1481, -0.1506,  0.7021]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6243, -0.2694,  0.5043]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.4272, -0.3005,  0.9500]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7541, -0.3023,  0.8192]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8207, -0.2625,  0.6335]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1878, -0.1042,  0.6873]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.9152, -0.0912,  0.4677]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.6360, -0.1703,  0.4127]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "#         print(output)\n",
    "#         print(output[0][1].item(), target.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss.append(loss.item())\n",
    "    print(sum(total_loss)/len(total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
