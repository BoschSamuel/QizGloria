{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phuembeli/Qiskit_develop/qiskit-terra/qiskit/pulse/channels/pulse_channels.py:25: DeprecationWarning: Channels have been migrated. Please use `from qiskit.pulse.channels import X` rather than `from qiskit.pulse.channels.pulse_channels import X`.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from qiskit import QuantumRegister,QuantumCircuit,ClassicalRegister,execute\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import Aer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to translate Q-Circuit parameters from pytorch back to QISKIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QiskitCircuit()\n",
    "\n",
    "Parameters have to be defined according to the circuit. In this case we have a unitary U3 with 3 parameters, which we call Theta, Phi and Lambda.\n",
    "The paramter `shots` always has to be defined. It gives the number of measurements done on the simulator or on the hardware to do the averages for the expectation values.\n",
    "\n",
    "### create_circuit()\n",
    "Define a quantum cirquit in QISKIT language\n",
    "\n",
    "### N_qubit_expectation_Z()\n",
    "This is a function that allows to take the measurements and translate them to Z-expectation values for every single qubit.\n",
    "\n",
    "### bind()\n",
    "Takes the Neural Network parameters and puts them into a format that can be fed into the QIKSIT unitaries.\n",
    "\n",
    "To generalze this code we would have to write a function that replaces the line `self.circuit.data[2][0]._params`.\n",
    "Because the `self.circuit.data` is a list of all the gates  of the circuit. And the indices direct to the correct gate, where the parameters have to go.\n",
    "\n",
    "At some point we would need a better scheme here.\n",
    "\n",
    "### run()\n",
    "This function puts the circuit with the given parameters on a quantum simulater or hardware and returns the measurements of every qubit in Z-basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T16:09:30.598730Z",
     "start_time": "2019-10-01T16:09:30.567861Z"
    }
   },
   "outputs": [],
   "source": [
    "class QiskitCircuit():\n",
    "    \n",
    "    def __init__(self,shots):\n",
    "        self.theta = Parameter('Theta')\n",
    "        self.phi = Parameter('Phi')\n",
    "        self.lam = Parameter('Lambda')\n",
    "        self.shots = shots\n",
    "        \n",
    "        def create_circuit():\n",
    "            qr = QuantumRegister(1,'q')\n",
    "            cr = ClassicalRegister(1,'c')\n",
    "            ckt = QuantumCircuit(qr,cr)\n",
    "            ckt.h(qr[0])\n",
    "            ckt.barrier()\n",
    "            ckt.u3(self.theta,self.phi,self.lam,qr[0])\n",
    "            ckt.barrier()\n",
    "            ckt.measure(qr,cr)\n",
    "            return ckt\n",
    "        \n",
    "        self.circuit = create_circuit()\n",
    "        \n",
    "    def N_qubit_expectation_Z(self,counts, shots, nr_qubits):\n",
    "        expects = np.zeros(nr_qubits)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects    \n",
    "    \n",
    "    def bind(self, parameters):\n",
    "        [self.theta,self.phi,self.lam] = to_numbers(parameters)\n",
    "        self.circuit.data[2][0]._params = to_numbers(parameters)\n",
    "    \n",
    "    def run(self, i):\n",
    "        self.bind(i)\n",
    "        \n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        job_sim = execute(self.circuit,backend,shots=self.shots)\n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        return self.N_qubit_expectation_Z(counts,self.shots,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchCircuit()\n",
    "\n",
    "A pytorch layer always has two functions. One for the forward pass and one for the backward pass. The forward pass simply takes the Quantum Circuits variational parameters from the previous pytorch layer and runs the circuit on the defined hardware (defined in `QiskitCircuit.run()`) and returns the measurements from the quantum hardware.\n",
    "These measurements will be the inputs of the next pytorch layer.\n",
    "\n",
    "The backward pass returns the gradients of the quantum circuit. In this case here it is finite difference.\n",
    "\n",
    "the `forward_tensor` is saved from the forward pass. So we just have to do one evaluation of the Q-Circuit in the backpass for the finite difference.\n",
    "\n",
    "The `gradient` variable here is as well hard coded to 3 parameters. This should be updated in the future and made more general.\n",
    "\n",
    "The loop `for k in range(len(input_numbers)):` goes through all the parameters (in this case 3), and shifts them by a small $\\epsilon$. Then it runs the circuit and takes the diefferences of the ouput for the parameters $\\Theta$ and $\\Theta + \\epsilon$. This is the finite difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit(shots=10000)\n",
    "            \n",
    "        exp_value = ctx.QiskitCirc.run(i[0])\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = 0.01\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors    \n",
    "        input_numbers = to_numbers(i[0])\n",
    "        gradient = [0,0,0]\n",
    "        \n",
    "        for k in range(len(input_numbers)):\n",
    "            input_eps = input_numbers\n",
    "            input_eps[k] = input_numbers[k] + eps\n",
    "\n",
    "            exp_value = ctx.QiskitCirc.run(torch.tensor(input_eps))[0]\n",
    "            result_eps = torch.tensor([exp_value])\n",
    "            gradient_result = (exp_value - forward_tensor[0][0].item())#/eps\n",
    "            gradient[k] = gradient_result\n",
    "            \n",
    "#         print(gradient)\n",
    "        result = torch.tensor([gradient])\n",
    "#         print(result)\n",
    "\n",
    "        return result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0206, 0.0210, 0.0104]])\n"
     ]
    }
   ],
   "source": [
    "# x = torch.tensor([np.pi/4, np.pi/4, np.pi/4], requires_grad=True)\n",
    "x = torch.tensor([[0.0, 0.0, 0.0]], requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "y1.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello World example\n",
    "\n",
    "Rotate 1 qubit to some position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1277a0b70>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = -1\n",
    "    expval = qc(x)\n",
    "    return torch.abs(qc(x) - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([[np.pi/4, np.pi/4, np.pi/4]], requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "    expval_list.append(expval.item())\n",
    "#     print(loss.item())\n",
    "\n",
    "plt.plot(loss_list)\n",
    "    \n",
    "# print(circuit(phi, theta))\n",
    "# print(cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST\n",
    "\n",
    "In this code we can not handle batches yet.\n",
    "This should be implemented as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:09, 1033422.94it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 91809.04it/s]                            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:02, 567437.39it/s]                             \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 29906.12it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 40\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size_train = 1\n",
    "batch_size_test = 1\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "labels = mnist_trainset.targets #get labels\n",
    "labels = labels.numpy()\n",
    "idx1 = np.where(labels == 0) #search all zeros\n",
    "idx2 = np.where(labels == 1) # search all ones\n",
    "idx = np.concatenate((idx1[0][0:20],idx2[0][0:20])) # concatenate their indices\n",
    "mnist_trainset.targets = labels[idx] \n",
    "mnist_trainset.data = mnist_trainset.data[idx]\n",
    "\n",
    "print(mnist_trainset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network with Q-node\n",
    "\n",
    "This NN is  2 layers of ConvNN and a fully connected layer, with a Q-Node as a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "#         return F.softmax(x)\n",
    "        x = np.pi*F.tanh(x)\n",
    "        x = qc(x) # This is the q node\n",
    "        x = (x+1)/2 # Translate expectation values [-1,1] to labels [0,1]\n",
    "        x = torch.cat((x, 1-x), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "# optimizer = optim.Adam(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "standard pytorch training loop.\n",
    "- Load data from train_loader. Which is this case a single example each step.\n",
    "- Forward pass through NN\n",
    "- Caluculate loss\n",
    "- Backprop and optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7789\n",
      "-0.8216\n",
      "-0.8955\n",
      "-0.99\n",
      "-0.8736\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "#         loss = F.cross_entropy(output, target)\n",
    "#         print(output)\n",
    "#         print(output[0][1].item(), target.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss.append(loss.item())\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy of NN\n",
    "\n",
    "The outcome is not always the same because the prediction is probabilistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "number = 0\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    number +=1\n",
    "    output = network(data)\n",
    "    output = (output>0.5).float()\n",
    "    accuracy += (output[0][1].item() == target[0].item())*1\n",
    "    \n",
    "print(\"Accuracy is: {}\".format(accuracy/number))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
