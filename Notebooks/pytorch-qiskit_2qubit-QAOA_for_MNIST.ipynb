{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- coding: utf-8 --\n",
    "# This code is part of Qiskit.\n",
    "#\n",
    "# (C) Copyright IBM 2019.\n",
    "#\n",
    "# This code is licensed under the Apache License, Version 2.0. You may\n",
    "# obtain a copy of this license in the LICENSE.txt file in the root directory\n",
    "# of this source tree or at http://www.apache.org/licenses/LICENSE-2.0.\n",
    "#\n",
    "# Any modifications or derivative works of this code must retain this\n",
    "# copyright notice, and modified files need to carry a notice indicating\n",
    "# that they have been altered from the originals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumRegister,QuantumCircuit,ClassicalRegister,execute\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit import Aer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from torch.autograd import Function\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numbers(tensor_list):\n",
    "    num_list = []\n",
    "    for tensor in tensor_list:\n",
    "        num_list += [tensor.item()]\n",
    "    return num_list\n",
    "\n",
    "class QiskitCircuit_QAOA():\n",
    "    def __init__(self,shots):\n",
    "        self.beta = Parameter('Beta')\n",
    "        self.gamma = Parameter('Gamma')\n",
    "        self.delta = Parameter('Delta')\n",
    "        self.beta2 = Parameter('Beta2')\n",
    "        self.delta2 = Parameter('Delta2')\n",
    "        self.shots = shots\n",
    "        \n",
    "        def create_circuit():\n",
    "            ckt = QuantumCircuit(2, 2)\n",
    "            # add mixer part\n",
    "            ckt.rx(self.beta, 0)\n",
    "            ckt.rx(self.beta2, 1)\n",
    "\n",
    "            # add H_target part, for each Zi Zj do this\n",
    "            ckt.cx(0,1)\n",
    "            ckt.rz(-1*self.gamma, 1)\n",
    "            ckt.cx(0,1)\n",
    "            ckt.ry(self.delta, 0)\n",
    "            ckt.ry(self.delta2, 1)\n",
    "            ckt.measure([0,1],[0,1])\n",
    "            return ckt\n",
    "\n",
    "        self.circuit = create_circuit()\n",
    "    \n",
    "    def expectation(self, counts, shots, nr_qubits): #calculate expectation for one qubit pair\n",
    "        expects = 0\n",
    "        #print(counts)\n",
    "        for key in counts.keys():\n",
    "            perc = counts[key]/shots\n",
    "            #check = Cij*((float(key[i])-1/2)+(float(key[j])-1/2))*perc\n",
    "            check = np.array([(float(key[i])-1/2)*2*perc for i in range(nr_qubits)])\n",
    "            expects += check   \n",
    "        return expects \n",
    "    \n",
    "    def bind(self,parameters):\n",
    "        [self.beta, self.beta2, self.gamma, self.delta, self.delta2] = parameters\n",
    "        #print(self.circuit.data)\n",
    "        self.circuit.data[0][0]._params = to_numbers(parameters)[0:1]\n",
    "        self.circuit.data[1][0]._params = to_numbers(parameters)[1:2]\n",
    "        self.circuit.data[3][0]._params = to_numbers(parameters)[2:3]\n",
    "        self.circuit.data[5][0]._params = to_numbers(parameters)[3:4]\n",
    "        self.circuit.data[6][0]._params = to_numbers(parameters)[4:5]\n",
    "        return self.circuit\n",
    " \n",
    "    def run(self, i):\n",
    "        self.bind(i)\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        job_sim = execute(self.circuit,backend,shots=self.shots)\n",
    "        result_sim = job_sim.result()\n",
    "        counts = result_sim.get_counts(self.circuit)\n",
    "        #print(counts)\n",
    "        return self.expectation(counts, self.shots, 2)    \n",
    "    \n",
    "class TorchCircuit(Function):    \n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, i):\n",
    "        if not hasattr(ctx, 'QiskitCirc'):\n",
    "            ctx.QiskitCirc = QiskitCircuit_QAOA(shots=10000)\n",
    "            \n",
    "        #print(i[0])    \n",
    "        exp_value = ctx.QiskitCirc.run(i[0])\n",
    "        \n",
    "        result = torch.tensor([exp_value])\n",
    "        \n",
    "        ctx.save_for_backward(result, i)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = 0.01\n",
    "        \n",
    "        forward_tensor, i = ctx.saved_tensors    \n",
    "        input_numbers = to_numbers(i[0])\n",
    "        \n",
    "        gradient = []\n",
    "        \n",
    "        for k in range(len(input_numbers)):\n",
    "            input_eps = input_numbers\n",
    "            input_eps[k] = input_numbers[k] + eps\n",
    "\n",
    "            exp_value = ctx.QiskitCirc.run(torch.tensor(input_eps))\n",
    "            result_eps = torch.tensor([exp_value])\n",
    "            gradient_result = (exp_value - forward_tensor[0][0].item())/eps\n",
    "            gradient.append(gradient_result)\n",
    "            \n",
    "#         print(gradient)\n",
    "        result = torch.tensor([gradient])\n",
    "        #print(grad_output.shape)\n",
    "        #print(result.shape)\n",
    "        #print(torch.einsum('abc,ac->ab',result.float(),grad_output.float()))\n",
    "        #print(\"test tens size\", result.float(), grad_output.float())\n",
    "        return torch.einsum('abc,ac->ab',result.float(),grad_output.float())#result.float() * grad_output.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9550, -0.9524]], dtype=torch.float64,\n",
      "       grad_fn=<TorchCircuitBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-57a1d7a63c95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/qiskit_develop/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qiskit_develop/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qiskit_develop/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "# x = torch.tensor([np.pi/4, np.pi/4, np.pi/4], requires_grad=True)\n",
    "x = torch.tensor([[0.3, 0.2, 0.1, 0.1, 0.2]], requires_grad=True)\n",
    "\n",
    "qc = TorchCircuit.apply\n",
    "y1 = qc(x)\n",
    "print(y1)\n",
    "y1 = torch.abs(y1[0] - 1.0) ** 2\n",
    "y1.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:25,  3.93it/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:00<00:24,  4.02it/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:00<00:23,  4.11it/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:00<00:22,  4.21it/s]\u001b[A\n",
      "  5%|▌         | 5/100 [00:01<00:22,  4.27it/s]\u001b[A\n",
      "  6%|▌         | 6/100 [00:01<00:21,  4.29it/s]\u001b[A\n",
      "  7%|▋         | 7/100 [00:01<00:21,  4.34it/s]\u001b[A\n",
      "  8%|▊         | 8/100 [00:01<00:21,  4.32it/s]\u001b[A\n",
      "  9%|▉         | 9/100 [00:02<00:21,  4.20it/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:02<00:21,  4.27it/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:02<00:20,  4.27it/s]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:02<00:21,  4.01it/s]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:03<00:21,  4.03it/s]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:03<00:21,  4.09it/s]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:03<00:20,  4.10it/s]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:03<00:19,  4.20it/s]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:04<00:19,  4.27it/s]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:04<00:19,  4.17it/s]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:04<00:19,  4.09it/s]\u001b[A\n",
      " 20%|██        | 20/100 [00:04<00:19,  4.11it/s]\u001b[A\n",
      " 21%|██        | 21/100 [00:05<00:18,  4.17it/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:05<00:18,  4.20it/s]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:05<00:17,  4.29it/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:05<00:17,  4.34it/s]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:05<00:17,  4.37it/s]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:06<00:16,  4.39it/s]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:06<00:16,  4.41it/s]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:06<00:17,  4.21it/s]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:06<00:16,  4.29it/s]\u001b[A\n",
      " 30%|███       | 30/100 [00:07<00:16,  4.31it/s]\u001b[A\n",
      " 31%|███       | 31/100 [00:07<00:15,  4.34it/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:07<00:15,  4.35it/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:07<00:15,  4.40it/s]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:07<00:14,  4.41it/s]\u001b[A\n",
      " 35%|███▌      | 35/100 [00:08<00:14,  4.40it/s]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:08<00:14,  4.34it/s]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:08<00:14,  4.39it/s]\u001b[A\n",
      " 38%|███▊      | 38/100 [00:08<00:14,  4.41it/s]\u001b[A\n",
      " 39%|███▉      | 39/100 [00:09<00:13,  4.38it/s]\u001b[A\n",
      " 40%|████      | 40/100 [00:09<00:13,  4.34it/s]\u001b[A\n",
      " 41%|████      | 41/100 [00:09<00:13,  4.39it/s]\u001b[A\n",
      " 42%|████▏     | 42/100 [00:09<00:13,  4.45it/s]\u001b[A\n",
      " 43%|████▎     | 43/100 [00:10<00:12,  4.46it/s]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:10<00:12,  4.44it/s]\u001b[A\n",
      " 45%|████▌     | 45/100 [00:10<00:12,  4.39it/s]\u001b[A\n",
      " 46%|████▌     | 46/100 [00:10<00:12,  4.43it/s]\u001b[A\n",
      " 47%|████▋     | 47/100 [00:10<00:11,  4.44it/s]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:11<00:11,  4.40it/s]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:11<00:11,  4.40it/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:11<00:11,  4.43it/s]\u001b[A\n",
      " 51%|█████     | 51/100 [00:11<00:11,  4.44it/s]\u001b[A\n",
      " 52%|█████▏    | 52/100 [00:12<00:10,  4.41it/s]\u001b[A\n",
      " 53%|█████▎    | 53/100 [00:12<00:10,  4.34it/s]\u001b[A\n",
      " 54%|█████▍    | 54/100 [00:12<00:10,  4.31it/s]\u001b[A\n",
      " 55%|█████▌    | 55/100 [00:12<00:10,  4.36it/s]\u001b[A\n",
      " 56%|█████▌    | 56/100 [00:12<00:10,  4.38it/s]\u001b[A\n",
      " 57%|█████▋    | 57/100 [00:13<00:09,  4.33it/s]\u001b[A\n",
      " 58%|█████▊    | 58/100 [00:13<00:09,  4.37it/s]\u001b[A\n",
      " 59%|█████▉    | 59/100 [00:13<00:09,  4.42it/s]\u001b[A\n",
      " 60%|██████    | 60/100 [00:13<00:09,  4.05it/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:14<00:09,  4.10it/s]\u001b[A\n",
      " 62%|██████▏   | 62/100 [00:14<00:09,  4.13it/s]\u001b[A\n",
      " 63%|██████▎   | 63/100 [00:14<00:08,  4.24it/s]\u001b[A\n",
      " 64%|██████▍   | 64/100 [00:14<00:08,  4.31it/s]\u001b[A\n",
      " 65%|██████▌   | 65/100 [00:15<00:08,  4.32it/s]\u001b[A\n",
      " 66%|██████▌   | 66/100 [00:15<00:07,  4.36it/s]\u001b[A\n",
      " 67%|██████▋   | 67/100 [00:15<00:07,  4.38it/s]\u001b[A\n",
      " 68%|██████▊   | 68/100 [00:15<00:07,  4.42it/s]\u001b[A\n",
      " 69%|██████▉   | 69/100 [00:16<00:07,  4.42it/s]\u001b[A\n",
      " 70%|███████   | 70/100 [00:16<00:06,  4.38it/s]\u001b[A\n",
      " 71%|███████   | 71/100 [00:16<00:06,  4.34it/s]\u001b[A\n",
      " 72%|███████▏  | 72/100 [00:16<00:06,  4.30it/s]\u001b[A\n",
      " 73%|███████▎  | 73/100 [00:16<00:06,  4.29it/s]\u001b[A\n",
      " 74%|███████▍  | 74/100 [00:17<00:06,  4.31it/s]\u001b[A\n",
      " 75%|███████▌  | 75/100 [00:17<00:05,  4.37it/s]\u001b[A\n",
      " 76%|███████▌  | 76/100 [00:17<00:05,  4.41it/s]\u001b[A\n",
      " 77%|███████▋  | 77/100 [00:17<00:05,  4.44it/s]\u001b[A\n",
      " 78%|███████▊  | 78/100 [00:18<00:05,  4.37it/s]\u001b[A\n",
      " 79%|███████▉  | 79/100 [00:18<00:04,  4.40it/s]\u001b[A\n",
      " 80%|████████  | 80/100 [00:18<00:04,  4.32it/s]\u001b[A\n",
      " 81%|████████  | 81/100 [00:18<00:04,  4.33it/s]\u001b[A\n",
      " 82%|████████▏ | 82/100 [00:19<00:04,  4.35it/s]\u001b[A\n",
      " 83%|████████▎ | 83/100 [00:19<00:04,  4.24it/s]\u001b[A\n",
      " 84%|████████▍ | 84/100 [00:19<00:03,  4.02it/s]\u001b[A\n",
      " 85%|████████▌ | 85/100 [00:19<00:03,  4.17it/s]\u001b[A\n",
      " 86%|████████▌ | 86/100 [00:20<00:03,  3.98it/s]\u001b[A\n",
      " 87%|████████▋ | 87/100 [00:20<00:03,  3.74it/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [00:20<00:03,  3.66it/s]\u001b[A\n",
      " 89%|████████▉ | 89/100 [00:20<00:02,  3.73it/s]\u001b[A\n",
      " 90%|█████████ | 90/100 [00:21<00:02,  3.70it/s]\u001b[A\n",
      " 91%|█████████ | 91/100 [00:21<00:02,  3.72it/s]\u001b[A\n",
      " 92%|█████████▏| 92/100 [00:21<00:02,  3.75it/s]\u001b[A\n",
      " 93%|█████████▎| 93/100 [00:21<00:01,  3.84it/s]\u001b[A\n",
      " 94%|█████████▍| 94/100 [00:22<00:01,  3.96it/s]\u001b[A\n",
      " 95%|█████████▌| 95/100 [00:22<00:01,  4.06it/s]\u001b[A\n",
      " 96%|█████████▌| 96/100 [00:22<00:00,  4.04it/s]\u001b[A\n",
      " 97%|█████████▋| 97/100 [00:22<00:00,  4.15it/s]\u001b[A\n",
      " 98%|█████████▊| 98/100 [00:23<00:00,  4.12it/s]\u001b[A\n",
      " 99%|█████████▉| 99/100 [00:23<00:00,  4.20it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:23<00:00,  4.24it/s]\u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12ebe06a0>]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qc = TorchCircuit.apply\n",
    "\n",
    "def cost(x):\n",
    "    target = 0.25\n",
    "    expval = qc(x)\n",
    "    return torch.abs(qc(x).sum() - target) ** 2, expval\n",
    "\n",
    "x = torch.tensor([[np.pi/4, np.pi/4, 1.0, 0.5, 0.1]], requires_grad=True)\n",
    "opt = torch.optim.Adam([x], lr=0.1)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "loss_list = []\n",
    "expval_list = []\n",
    "\n",
    "for i in tqdm(range(num_epoch)):\n",
    "# for i in range(num_epoch):\n",
    "    opt.zero_grad()\n",
    "    loss, expval = cost(x)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    loss_list.append(loss.item())\n",
    "#     print(loss.item())\n",
    "\n",
    "plt.plot(loss_list)\n",
    "    \n",
    "# print(circuit(phi, theta))\n",
    "# print(cost(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 20\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "batch_size_train = 1\n",
    "batch_size_test = 1\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "torch.backends.cudnn.enabled = False\n",
    "\n",
    "transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "labels = mnist_trainset.targets #get labels\n",
    "labels = labels.numpy()\n",
    "idx1 = np.where(labels == 0) #search all zeros\n",
    "idx2 = np.where(labels == 1) # search all ones\n",
    "idx = np.concatenate((idx1[0][0:10],idx2[0][0:10])) # concatenate their indices\n",
    "#idx = idx2\n",
    "mnist_trainset.targets = labels[idx] \n",
    "mnist_trainset.data = mnist_trainset.data[idx]\n",
    "\n",
    "print(mnist_trainset)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        #x = np.pi*F.tanh(x)\n",
    "        #print(x)\n",
    "        x = qc(x)\n",
    "        x = (x+1)/2\n",
    "#         print(x)\n",
    "        #x = torch.cat((x, 1-x), -1)\n",
    "#        return x\n",
    "        return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phuembeli/anaconda3/envs/qiskit_develop/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5029, 0.4971], dtype=torch.float64) tensor([0])\n",
      "tensor([0.4989, 0.5011], dtype=torch.float64) tensor([1])\n",
      "tensor([0.4991, 0.5009], dtype=torch.float64) tensor([0])\n",
      "tensor([0.4992, 0.5008], dtype=torch.float64) tensor([1])\n",
      "tensor([0.4995, 0.5005], dtype=torch.float64) tensor([1])\n",
      "tensor([0.4999, 0.5001], dtype=torch.float64) tensor([1])\n",
      "tensor([0.4986, 0.5014], dtype=torch.float64) tensor([1])\n",
      "tensor([0.4995, 0.5005], dtype=torch.float64) tensor([0])\n",
      "tensor([0.4982, 0.5018], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5000, 0.5000], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5026, 0.4974], dtype=torch.float64) tensor([0])\n",
      "tensor([0.4999, 0.5001], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5038, 0.4962], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5005, 0.4995], dtype=torch.float64) tensor([0])\n",
      "tensor([0.4990, 0.5010], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5006, 0.4994], dtype=torch.float64) tensor([1])\n",
      "tensor([0.4999, 0.5001], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5006, 0.4994], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5017, 0.4983], dtype=torch.float64) tensor([0])\n",
      "tensor([0.4997, 0.5003], dtype=torch.float64) tensor([1])\n",
      "-0.5006937425890285\n",
      "tensor([0.5005, 0.4995], dtype=torch.float64) tensor([1])\n",
      "tensor([0.4997, 0.5003], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5001, 0.4999], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5019, 0.4981], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5020, 0.4980], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5020, 0.4980], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5045, 0.4955], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5084, 0.4916], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5026, 0.4974], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5011, 0.4989], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5011, 0.4989], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5011, 0.4989], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5046, 0.4954], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5167, 0.4833], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5122, 0.4878], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5072, 0.4928], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5012, 0.4988], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5103, 0.4897], dtype=torch.float64) tensor([0])\n",
      "tensor([0.4876, 0.5124], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5278, 0.4722], dtype=torch.float64) tensor([1])\n",
      "-0.5001160314637565\n",
      "tensor([0.5018, 0.4982], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5011, 0.4989], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5006, 0.4994], dtype=torch.float64) tensor([1])\n",
      "tensor([0.6753, 0.3247], dtype=torch.float64) tensor([0])\n",
      "tensor([0.3651, 0.6349], dtype=torch.float64) tensor([0])\n",
      "tensor([0.4149, 0.5851], dtype=torch.float64) tensor([0])\n",
      "tensor([0.4487, 0.5513], dtype=torch.float64) tensor([1])\n",
      "tensor([0.4966, 0.5034], dtype=torch.float64) tensor([0])\n",
      "tensor([0.4873, 0.5127], dtype=torch.float64) tensor([1])\n",
      "tensor([0.4713, 0.5287], dtype=torch.float64) tensor([0])\n",
      "tensor([0.5843, 0.4157], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5883, 0.4117], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5180, 0.4820], dtype=torch.float64) tensor([1])\n",
      "tensor([0.5322, 0.4678], dtype=torch.float64) tensor([1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[json.exception.parse_error.101] parse error at 122: syntax error - invalid literal; last read: '\"params\": [[N'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-7a8a5a75a974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#print(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qiskit_develop/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-143-66b89fb1bf70>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#x = np.pi*F.tanh(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#         print(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-e8469d10d02f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, i)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m#print(i[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mexp_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQiskitCirc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-e8469d10d02f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'qasm_simulator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mjob_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mresult_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m#print(counts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qiskit_develop/lib/python3.7/site-packages/qiskit/providers/aer/aerjob.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mJobError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job not submitted yet!. You have to .submit() first!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qiskit_develop/lib/python3.7/site-packages/qiskit/providers/aer/aerjob.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mjob\u001b[0m \u001b[0mcancelled\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mrequires_submit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qiskit_develop/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qiskit_develop/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qiskit_develop/lib/python3.7/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/qiskit_develop/lib/python3.7/site-packages/qiskit/providers/aer/backends/aerbackend.py\u001b[0m in \u001b[0;36m_run_job\u001b[0;34m(self, job_id, qobj, backend_options, noise_model, validate)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mqobj_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format_qobj_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_controller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqobj_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'UTF-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_controller_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mqasm_controller_wrapper.pyx\u001b[0m in \u001b[0;36mqasm_controller_wrapper.qasm_controller_execute\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [json.exception.parse_error.101] parse error at 122: syntax error - invalid literal; last read: '\"params\": [[N'"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         print(batch_idx)\n",
    "        optimizer.zero_grad()\n",
    "        #print(data)\n",
    "        output = network(data)\n",
    "        print(output[0].data, target)\n",
    "        loss = F.nll_loss(output, target)\n",
    "#         print(output)\n",
    "#         print(output[0][1].item(), target.item())\n",
    "        #print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss.append(loss.item())\n",
    "    print(sum(total_loss)/len(total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
